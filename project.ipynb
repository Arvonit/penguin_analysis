{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SeeFood \n",
    "\n",
    "For our final project, we wrote a Convolutional Neural Network (CNN) that recognizes whether a \n",
    "food image is or is not a hot dog. Our dataset is from [Kaggle](https://www.kaggle.com/datasets/dansbecker/hot-dog-not-hot-dog?datasetId=8552&sortBy=relevance&searchQuery=CNN),\n",
    "which is compiled from a dataset of 101 different food items. It is separated into test and train \n",
    "folders from the get-go, each with 250 pictures of hot dogs and 250 pictures of other food items. So there is a total of 1000 pictures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "        .bk-notebook-logo {\n",
       "            display: block;\n",
       "            width: 20px;\n",
       "            height: 20px;\n",
       "            background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAABx0RVh0U29mdHdhcmUAQWRvYmUgRmlyZXdvcmtzIENTNui8sowAAAOkSURBVDiNjZRtaJVlGMd/1/08zzln5zjP1LWcU9N0NkN8m2CYjpgQYQXqSs0I84OLIC0hkEKoPtiH3gmKoiJDU7QpLgoLjLIQCpEsNJ1vqUOdO7ppbuec5+V+rj4ctwzd8IIbbi6u+8f1539dt3A78eXC7QizUF7gyV1fD1Yqg4JWz84yffhm0qkFqBogB9rM8tZdtwVsPUhWhGcFJngGeWrPzHm5oaMmkfEg1usvLFyc8jLRqDOMru7AyC8saQr7GG7f5fvDeH7Ej8CM66nIF+8yngt6HWaKh7k49Soy9nXurCi1o3qUbS3zWfrYeQDTB/Qj6kX6Ybhw4B+bOYoLKCC9H3Nu/leUTZ1JdRWkkn2ldcCamzrcf47KKXdAJllSlxAOkRgyHsGC/zRday5Qld9DyoM4/q/rUoy/CXh3jzOu3bHUVZeU+DEn8FInkPBFlu3+nW3Nw0mk6vCDiWg8CeJaxEwuHS3+z5RgY+YBR6V1Z1nxSOfoaPa4LASWxxdNp+VWTk7+4vzaou8v8PN+xo+KY2xsw6une2frhw05CTYOmQvsEhjhWjn0bmXPjpE1+kplmmkP3suftwTubK9Vq22qKmrBhpY4jvd5afdRA3wGjFAgcnTK2s4hY0/GPNIb0nErGMCRxWOOX64Z8RAC4oCXdklmEvcL8o0BfkNK4lUg9HTl+oPlQxdNo3Mg4Nv175e/1LDGzZen30MEjRUtmXSfiTVu1kK8W4txyV6BMKlbgk3lMwYCiusNy9fVfvvwMxv8Ynl6vxoByANLTWplvuj/nF9m2+PDtt1eiHPBr1oIfhCChQMBw6Aw0UulqTKZdfVvfG7VcfIqLG9bcldL/+pdWTLxLUy8Qq38heUIjh4XlzZxzQm19lLFlr8vdQ97rjZVOLf8nclzckbcD4wxXMidpX30sFd37Fv/GtwwhzhxGVAprjbg0gCAEeIgwCZyTV2Z1REEW8O4py0wsjeloKoMr6iCY6dP92H6Vw/oTyICIthibxjm/DfN9lVz8IqtqKYLUXfoKVMVQVVJOElGjrnnUt9T9wbgp8AyYKaGlqingHZU/uG2NTZSVqwHQTWkx9hxjkpWDaCg6Ckj5qebgBVbT3V3NNXMSiWSDdGV3hrtzla7J+duwPOToIg42ChPQOQjspnSlp1V+Gjdged7+8UN5CRAV7a5EdFNwCjEaBR27b3W890TE7g24NAP/mMDXRWrGoFPQI9ls/MWO2dWFAar/xcOIImbbpA3zgAAAABJRU5ErkJggg==);\n",
       "        }\n",
       "    </style>\n",
       "    <div>\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-notebook-logo\"></a>\n",
       "        <span id=\"p1384\">Loading BokehJS ...</span>\n",
       "    </div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\nconst JS_MIME_TYPE = 'application/javascript';\n  const HTML_MIME_TYPE = 'text/html';\n  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n  const CLASS_NAME = 'output_bokeh rendered_html';\n\n  /**\n   * Render data to the DOM node\n   */\n  function render(props, node) {\n    const script = document.createElement(\"script\");\n    node.appendChild(script);\n  }\n\n  /**\n   * Handle when an output is cleared or removed\n   */\n  function handleClearOutput(event, handle) {\n    const cell = handle.cell;\n\n    const id = cell.output_area._bokeh_element_id;\n    const server_id = cell.output_area._bokeh_server_id;\n    // Clean up Bokeh references\n    if (id != null && id in Bokeh.index) {\n      Bokeh.index[id].model.document.clear();\n      delete Bokeh.index[id];\n    }\n\n    if (server_id !== undefined) {\n      // Clean up Bokeh references\n      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n      cell.notebook.kernel.execute(cmd_clean, {\n        iopub: {\n          output: function(msg) {\n            const id = msg.content.text.trim();\n            if (id in Bokeh.index) {\n              Bokeh.index[id].model.document.clear();\n              delete Bokeh.index[id];\n            }\n          }\n        }\n      });\n      // Destroy server and session\n      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n      cell.notebook.kernel.execute(cmd_destroy);\n    }\n  }\n\n  /**\n   * Handle when a new output is added\n   */\n  function handleAddOutput(event, handle) {\n    const output_area = handle.output_area;\n    const output = handle.output;\n\n    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n      return\n    }\n\n    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n\n    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n      // store reference to embed id on output_area\n      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n    }\n    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n      const bk_div = document.createElement(\"div\");\n      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n      const script_attrs = bk_div.children[0].attributes;\n      for (let i = 0; i < script_attrs.length; i++) {\n        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n      }\n      // store reference to server id on output_area\n      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n    }\n  }\n\n  function register_renderer(events, OutputArea) {\n\n    function append_mime(data, metadata, element) {\n      // create a DOM node to render to\n      const toinsert = this.create_output_subarea(\n        metadata,\n        CLASS_NAME,\n        EXEC_MIME_TYPE\n      );\n      this.keyboard_manager.register_events(toinsert);\n      // Render to node\n      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n      render(props, toinsert[toinsert.length - 1]);\n      element.append(toinsert);\n      return toinsert\n    }\n\n    /* Handle when an output is cleared or removed */\n    events.on('clear_output.CodeCell', handleClearOutput);\n    events.on('delete.Cell', handleClearOutput);\n\n    /* Handle when a new output is added */\n    events.on('output_added.OutputArea', handleAddOutput);\n\n    /**\n     * Register the mime type and append_mime function with output_area\n     */\n    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n      /* Is output safe? */\n      safe: true,\n      /* Index of renderer in `output_area.display_order` */\n      index: 0\n    });\n  }\n\n  // register the mime type if in Jupyter Notebook environment and previously unregistered\n  if (root.Jupyter !== undefined) {\n    const events = require('base/js/events');\n    const OutputArea = require('notebook/js/outputarea').OutputArea;\n\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  }\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    const el = document.getElementById(\"p1384\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.1.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.1.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.1.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.1.0.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.1.0.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n          for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\nif (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"p1384\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));",
      "application/vnd.bokehjs_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.regularizers import l1, l2\n",
    "from keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D, BatchNormalization\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from bokeh.plotting import figure, output_notebook, show\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import imgaug.augmenters as iaa\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from PIL import Image\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are constants we use throughout the project, including number of epochs and image dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 50, 50\n",
    "input_shape = (img_width, img_height, 1)\n",
    "batch_size = 25\n",
    "num_epochs = 25\n",
    "num_classes = 2\n",
    "validation_split = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image Preprocessing\n",
    "\n",
    "Here we load the images from the dataset. Based on the `data_type` and `class_type` arguments, we can load test and train data, split into the `hot_dog` and `not_hot_dog` classes.\n",
    "\n",
    "Because the images of are of various sizes and in color, we have to do some preprocessing to the pictures. We first load\n",
    "it in grayscale, so that it easier for the neural network to process. Then, we resize the image to\n",
    "50 x 50 px."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_type, class_type):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for file in os.listdir(f'data/{data_type}/{class_type}'):\n",
    "        image = cv2.resize(cv2.imread(f'data/{data_type}/{class_type}/{format(file)}', 0), (img_width, img_height))\n",
    "        images.append(image)\n",
    "        labels.append(1 if class_type == 'not_hot_dog' else 0)\n",
    "\n",
    "    return (images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and merge training data\n",
    "X_train_nh, y_train_nh = load_data(data_type=\"train\", class_type=\"not_hot_dog\")\n",
    "X_train_h, y_train_h = load_data(data_type=\"train\", class_type=\"hot_dog\")\n",
    "X_train = np.array(X_train_nh + X_train_h)\n",
    "\n",
    "# rotation_layer = RandomRotation(0.5)\n",
    "# rotation_layer = RandomZoom()\n",
    "# X_train_aug = rotation_layer(X_train).numpy()\n",
    "\n",
    "# X_train = np.array(X_train + X_train_aug)\n",
    "\n",
    "X_train = X_train.reshape((X_train.shape[0], img_width, img_height, 1))\n",
    "y_train = np.array(y_train_nh + y_train_h)\n",
    "\n",
    "# load and merge testing data\n",
    "X_test_nh, y_test_nh = load_data(data_type=\"test\", class_type=\"not_hot_dog\")\n",
    "X_test_h, y_test_h = load_data(data_type=\"test\", class_type=\"hot_dog\")\n",
    "X_test = np.array(X_test_nh + X_test_h)\n",
    "X_test = X_test.reshape((X_test.shape[0], img_width, img_height, 1))\n",
    "y_test = np.array(y_test_nh + y_test_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A picture of french fries and a hot dog after the preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "axes[0].imshow(X_train_nh[0], cmap=\"gray\")\n",
    "axes[0].set_title(\"Not hot dog\")\n",
    "axes[0].axis(\"off\")\n",
    "\n",
    "axes[1].imshow(X_train_h[0], cmap=\"gray\")\n",
    "axes[1].set_title(\"Hot dog\")\n",
    "axes[1].axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Network\n",
    "\n",
    "Our neural network is a CNN with multiple layers. The first three layers are convolutional layers: (1) input layer with 25 filters, (2) secondary layer with 50 filters, (3) third layer with 100 filters. These convolutional layers are used to extract features from the input images, with each layer learning increasingly complex patterns. The next layer flattens the multidimensional output into a one dimensional layer. This is needed for the dense layers, which are fully connected with 256 neurons and give us our output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(25, kernel_size=(3, 3), activation=\"relu\", input_shape=input_shape))\n",
    "model.add(Conv2D(50, kernel_size=(3, 3), activation=\"relu\"))\n",
    "model.add(Conv2D(100, kernel_size=(3, 3), activation=\"relu\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation=\"relu\"))\n",
    "model.add(Dense(num_classes, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=tensorflow.keras.losses.sparse_categorical_crossentropy,\n",
    "              optimizer=tensorflow.keras.optimizers.Adam(),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "16/16 [==============================] - 2s 69ms/step - loss: 509.0888 - accuracy: 0.5201 - val_loss: 1.1900 - val_accuracy: 0.0900\n",
      "Epoch 2/25\n",
      "16/16 [==============================] - 1s 58ms/step - loss: 0.5335 - accuracy: 0.7462 - val_loss: 0.7739 - val_accuracy: 0.5300\n",
      "Epoch 3/25\n",
      "16/16 [==============================] - 1s 60ms/step - loss: 0.2871 - accuracy: 0.9045 - val_loss: 1.2961 - val_accuracy: 0.4700\n",
      "Epoch 4/25\n",
      "16/16 [==============================] - 1s 54ms/step - loss: 0.1430 - accuracy: 0.9447 - val_loss: 0.9536 - val_accuracy: 0.6000\n",
      "Epoch 5/25\n",
      "16/16 [==============================] - 1s 53ms/step - loss: 0.0533 - accuracy: 0.9975 - val_loss: 3.1481 - val_accuracy: 0.2900\n",
      "Epoch 6/25\n",
      "16/16 [==============================] - 1s 54ms/step - loss: 0.0417 - accuracy: 0.9899 - val_loss: 3.8277 - val_accuracy: 0.1200\n",
      "Epoch 7/25\n",
      "16/16 [==============================] - 1s 53ms/step - loss: 0.0176 - accuracy: 0.9975 - val_loss: 2.8116 - val_accuracy: 0.3800\n",
      "Epoch 8/25\n",
      "16/16 [==============================] - 1s 53ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 3.0538 - val_accuracy: 0.3900\n",
      "Epoch 9/25\n",
      "16/16 [==============================] - 1s 56ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 4.0352 - val_accuracy: 0.3300\n",
      "Epoch 10/25\n",
      "16/16 [==============================] - 1s 56ms/step - loss: 5.5102e-04 - accuracy: 1.0000 - val_loss: 4.0365 - val_accuracy: 0.3700\n",
      "Epoch 11/25\n",
      "16/16 [==============================] - 1s 54ms/step - loss: 3.0976e-04 - accuracy: 1.0000 - val_loss: 4.1106 - val_accuracy: 0.3800\n",
      "Epoch 12/25\n",
      "16/16 [==============================] - 1s 54ms/step - loss: 1.9364e-04 - accuracy: 1.0000 - val_loss: 4.4216 - val_accuracy: 0.3700\n",
      "Epoch 13/25\n",
      "16/16 [==============================] - 1s 53ms/step - loss: 1.3387e-04 - accuracy: 1.0000 - val_loss: 4.4922 - val_accuracy: 0.3800\n",
      "Epoch 14/25\n",
      "16/16 [==============================] - 1s 53ms/step - loss: 9.1349e-05 - accuracy: 1.0000 - val_loss: 4.8999 - val_accuracy: 0.3200\n",
      "Epoch 15/25\n",
      "16/16 [==============================] - 1s 53ms/step - loss: 5.7538e-05 - accuracy: 1.0000 - val_loss: 4.3041 - val_accuracy: 0.3900\n",
      "Epoch 16/25\n",
      "16/16 [==============================] - 1s 53ms/step - loss: 3.0648e-05 - accuracy: 1.0000 - val_loss: 5.2588 - val_accuracy: 0.3500\n",
      "Epoch 17/25\n",
      "16/16 [==============================] - 1s 53ms/step - loss: 1.5883e-05 - accuracy: 1.0000 - val_loss: 5.7990 - val_accuracy: 0.3400\n",
      "Epoch 18/25\n",
      "16/16 [==============================] - 1s 54ms/step - loss: 9.6710e-06 - accuracy: 1.0000 - val_loss: 5.1228 - val_accuracy: 0.3700\n",
      "Epoch 19/25\n",
      "16/16 [==============================] - 1s 53ms/step - loss: 6.0976e-06 - accuracy: 1.0000 - val_loss: 4.3825 - val_accuracy: 0.4000\n",
      "Epoch 20/25\n",
      "16/16 [==============================] - 1s 53ms/step - loss: 5.3444e-06 - accuracy: 1.0000 - val_loss: 7.8539 - val_accuracy: 0.3100\n",
      "Epoch 21/25\n",
      "16/16 [==============================] - 1s 53ms/step - loss: 1.0541e-05 - accuracy: 1.0000 - val_loss: 4.0715 - val_accuracy: 0.4000\n",
      "Epoch 22/25\n",
      "16/16 [==============================] - 1s 53ms/step - loss: 7.7672e-06 - accuracy: 1.0000 - val_loss: 6.7570 - val_accuracy: 0.2700\n",
      "Epoch 23/25\n",
      "16/16 [==============================] - 1s 54ms/step - loss: 4.0832e-05 - accuracy: 1.0000 - val_loss: 5.1741 - val_accuracy: 0.3400\n",
      "Epoch 24/25\n",
      "16/16 [==============================] - 1s 53ms/step - loss: 5.6109e-05 - accuracy: 1.0000 - val_loss: 4.8393 - val_accuracy: 0.3500\n",
      "Epoch 25/25\n",
      "16/16 [==============================] - 1s 53ms/step - loss: 4.0231e-05 - accuracy: 1.0000 - val_loss: 5.4633 - val_accuracy: 0.3200\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=num_epochs,\n",
    "                    shuffle=True,\n",
    "                    validation_split=validation_split)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running the model for 25 epochs, we have a pretty mediocre accuracy of around 50%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 26ms/step - loss: 3.2336 - accuracy: 0.5440\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate our model, we show the confusion matrix and some metrics. Our confusion matrix leans\n",
    "toward positives (hot dog) than negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 24ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 74, 176],\n",
       "       [ 52, 198]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.argmax(model.predict(X_test), axis=-1)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.544000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.529412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.792000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F1</td>\n",
       "      <td>0.634615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Metric     Value\n",
       "0   Accuracy  0.544000\n",
       "1  Precision  0.529412\n",
       "2     Recall  0.792000\n",
       "3         F1  0.634615"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn, fp, fn, tp = cm.ravel()\n",
    "pd.DataFrame({\n",
    "    \"Metric\": [\"Accuracy\", \"Precision\", \"Recall\", \"F1\"],\n",
    "    \"Value\": [(tp+tn)/(tp+fp+fn+tn), tp/(tp+fp), tp/(tp+fn), (2*tp/(tp+fp))*(tp/(tp+fn)) / ((tp/(tp+fp))+(tp/(tp+fn)))]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a plot showing the training and validation loss along with their accuracy. As you can see, the validation loss and accuracy are not very good for this model. They don't converge with the rest of the training data. We believe this is because the network overfits to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"0205b97d-7434-4ec2-9b28-fb57a7dd60ee\" data-root-id=\"p1002\" style=\"display: contents;\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function embed_document(root) {\n  const docs_json = {\"972f86e7-3305-4f4e-bd39-2d776efa6b6d\":{\"version\":\"3.1.0\",\"title\":\"Bokeh Application\",\"defs\":[],\"roots\":[{\"type\":\"object\",\"name\":\"Figure\",\"id\":\"p1002\",\"attributes\":{\"x_range\":{\"type\":\"object\",\"name\":\"DataRange1d\",\"id\":\"p1003\"},\"y_range\":{\"type\":\"object\",\"name\":\"DataRange1d\",\"id\":\"p1004\"},\"x_scale\":{\"type\":\"object\",\"name\":\"LinearScale\",\"id\":\"p1016\"},\"y_scale\":{\"type\":\"object\",\"name\":\"LinearScale\",\"id\":\"p1018\"},\"title\":{\"type\":\"object\",\"name\":\"Title\",\"id\":\"p1005\",\"attributes\":{\"text\":\"Training and Validation Loss\"}},\"renderers\":[{\"type\":\"object\",\"name\":\"GlyphRenderer\",\"id\":\"p1055\",\"attributes\":{\"data_source\":{\"type\":\"object\",\"name\":\"ColumnDataSource\",\"id\":\"p1049\",\"attributes\":{\"selected\":{\"type\":\"object\",\"name\":\"Selection\",\"id\":\"p1050\",\"attributes\":{\"indices\":[],\"line_indices\":[]}},\"selection_policy\":{\"type\":\"object\",\"name\":\"UnionRenderers\",\"id\":\"p1051\"},\"data\":{\"type\":\"map\",\"entries\":[[\"x\",[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]],[\"y\",[409.7406311035156,0.5488243103027344,0.3043915033340454,0.10629458725452423,0.018339838832616806,0.0021430710330605507,0.000439249852206558,0.0001270614011446014,1.3180248060962185e-05,6.8737053879885934e-06,4.953021289111348e-06,3.891277629008982e-06,3.3222147521883016e-06,2.8633696729229996e-06,2.5234244276362006e-06,2.2041460852051387e-06,1.958844677574234e-06,1.725224024085037e-06,1.5365299077529926e-06,1.3945586943009403e-06,1.2531870652310317e-06,1.1354769640092854e-06,1.0303464250682737e-06,9.533702609587635e-07,8.781912583799567e-07]]]}}},\"view\":{\"type\":\"object\",\"name\":\"CDSView\",\"id\":\"p1056\",\"attributes\":{\"filter\":{\"type\":\"object\",\"name\":\"AllIndices\",\"id\":\"p1057\"}}},\"glyph\":{\"type\":\"object\",\"name\":\"Line\",\"id\":\"p1052\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"line_color\":\"blue\"}},\"nonselection_glyph\":{\"type\":\"object\",\"name\":\"Line\",\"id\":\"p1053\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"line_color\":\"blue\",\"line_alpha\":0.1}},\"muted_glyph\":{\"type\":\"object\",\"name\":\"Line\",\"id\":\"p1054\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"line_color\":\"blue\",\"line_alpha\":0.2}}}},{\"type\":\"object\",\"name\":\"GlyphRenderer\",\"id\":\"p1066\",\"attributes\":{\"data_source\":{\"type\":\"object\",\"name\":\"ColumnDataSource\",\"id\":\"p1060\",\"attributes\":{\"selected\":{\"type\":\"object\",\"name\":\"Selection\",\"id\":\"p1061\",\"attributes\":{\"indices\":[],\"line_indices\":[]}},\"selection_policy\":{\"type\":\"object\",\"name\":\"UnionRenderers\",\"id\":\"p1062\"},\"data\":{\"type\":\"map\",\"entries\":[[\"x\",[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]],[\"y\",[1.6327918767929077,1.7858127355575562,1.7941677570343018,2.448458433151245,5.899871349334717,5.637704849243164,5.081623077392578,4.648051738739014,6.115548133850098,6.339773178100586,6.192687511444092,6.14599609375,6.126816272735596,6.142987251281738,6.1870622634887695,6.197668552398682,6.2393412590026855,6.236102104187012,6.248459339141846,6.264080047607422,6.286948204040527,6.338581562042236,6.360674858093262,6.362981796264648,6.411909103393555]]]}}},\"view\":{\"type\":\"object\",\"name\":\"CDSView\",\"id\":\"p1067\",\"attributes\":{\"filter\":{\"type\":\"object\",\"name\":\"AllIndices\",\"id\":\"p1068\"}}},\"glyph\":{\"type\":\"object\",\"name\":\"Line\",\"id\":\"p1063\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"line_color\":\"red\"}},\"nonselection_glyph\":{\"type\":\"object\",\"name\":\"Line\",\"id\":\"p1064\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"line_color\":\"red\",\"line_alpha\":0.1}},\"muted_glyph\":{\"type\":\"object\",\"name\":\"Line\",\"id\":\"p1065\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"line_color\":\"red\",\"line_alpha\":0.2}}}}],\"toolbar\":{\"type\":\"object\",\"name\":\"Toolbar\",\"id\":\"p1008\",\"attributes\":{\"tools\":[{\"type\":\"object\",\"name\":\"PanTool\",\"id\":\"p1034\"},{\"type\":\"object\",\"name\":\"WheelZoomTool\",\"id\":\"p1035\"},{\"type\":\"object\",\"name\":\"BoxZoomTool\",\"id\":\"p1036\",\"attributes\":{\"overlay\":{\"type\":\"object\",\"name\":\"BoxAnnotation\",\"id\":\"p1037\",\"attributes\":{\"syncable\":false,\"level\":\"overlay\",\"visible\":false,\"left_units\":\"canvas\",\"right_units\":\"canvas\",\"bottom_units\":\"canvas\",\"top_units\":\"canvas\",\"line_color\":\"black\",\"line_alpha\":1.0,\"line_width\":2,\"line_dash\":[4,4],\"fill_color\":\"lightgrey\",\"fill_alpha\":0.5}}}},{\"type\":\"object\",\"name\":\"SaveTool\",\"id\":\"p1038\"},{\"type\":\"object\",\"name\":\"ResetTool\",\"id\":\"p1039\"},{\"type\":\"object\",\"name\":\"HelpTool\",\"id\":\"p1040\"}]}},\"left\":[{\"type\":\"object\",\"name\":\"LinearAxis\",\"id\":\"p1027\",\"attributes\":{\"ticker\":{\"type\":\"object\",\"name\":\"BasicTicker\",\"id\":\"p1029\",\"attributes\":{\"mantissas\":[1,2,5]}},\"formatter\":{\"type\":\"object\",\"name\":\"BasicTickFormatter\",\"id\":\"p1030\"},\"axis_label\":\"Loss\",\"major_label_policy\":{\"type\":\"object\",\"name\":\"AllLabels\",\"id\":\"p1028\"}}}],\"below\":[{\"type\":\"object\",\"name\":\"LinearAxis\",\"id\":\"p1020\",\"attributes\":{\"ticker\":{\"type\":\"object\",\"name\":\"BasicTicker\",\"id\":\"p1022\",\"attributes\":{\"mantissas\":[1,2,5]}},\"formatter\":{\"type\":\"object\",\"name\":\"BasicTickFormatter\",\"id\":\"p1023\"},\"axis_label\":\"Epoch\",\"major_label_policy\":{\"type\":\"object\",\"name\":\"AllLabels\",\"id\":\"p1021\"}}}],\"center\":[{\"type\":\"object\",\"name\":\"Grid\",\"id\":\"p1026\",\"attributes\":{\"axis\":{\"id\":\"p1020\"}}},{\"type\":\"object\",\"name\":\"Grid\",\"id\":\"p1033\",\"attributes\":{\"dimension\":1,\"axis\":{\"id\":\"p1027\"}}},{\"type\":\"object\",\"name\":\"Legend\",\"id\":\"p1058\",\"attributes\":{\"items\":[{\"type\":\"object\",\"name\":\"LegendItem\",\"id\":\"p1059\",\"attributes\":{\"label\":{\"type\":\"value\",\"value\":\"Train Loss\"},\"renderers\":[{\"id\":\"p1055\"}]}},{\"type\":\"object\",\"name\":\"LegendItem\",\"id\":\"p1069\",\"attributes\":{\"label\":{\"type\":\"value\",\"value\":\"Validation Loss\"},\"renderers\":[{\"id\":\"p1066\"}]}}]}}]}}],\"callbacks\":{\"type\":\"map\"}}};\n  const render_items = [{\"docid\":\"972f86e7-3305-4f4e-bd39-2d776efa6b6d\",\"roots\":{\"p1002\":\"0205b97d-7434-4ec2-9b28-fb57a7dd60ee\"},\"root_ids\":[\"p1002\"]}];\n  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n  }\n  if (root.Bokeh !== undefined) {\n    embed_document(root);\n  } else {\n    let attempts = 0;\n    const timer = setInterval(function(root) {\n      if (root.Bokeh !== undefined) {\n        clearInterval(timer);\n        embed_document(root);\n      } else {\n        attempts++;\n        if (attempts > 100) {\n          clearInterval(timer);\n          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n        }\n      }\n    }, 10, root)\n  }\n})(window);",
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "p1002"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"66dbfd25-b82b-491e-aeaa-ed5d3dd0de67\" data-root-id=\"p1184\" style=\"display: contents;\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function embed_document(root) {\n  const docs_json = {\"6e977b72-4ff3-428f-a872-1385caf84b1c\":{\"version\":\"3.1.0\",\"title\":\"Bokeh Application\",\"defs\":[],\"roots\":[{\"type\":\"object\",\"name\":\"Figure\",\"id\":\"p1184\",\"attributes\":{\"x_range\":{\"type\":\"object\",\"name\":\"DataRange1d\",\"id\":\"p1185\"},\"y_range\":{\"type\":\"object\",\"name\":\"DataRange1d\",\"id\":\"p1186\"},\"x_scale\":{\"type\":\"object\",\"name\":\"LinearScale\",\"id\":\"p1198\"},\"y_scale\":{\"type\":\"object\",\"name\":\"LinearScale\",\"id\":\"p1200\"},\"title\":{\"type\":\"object\",\"name\":\"Title\",\"id\":\"p1187\",\"attributes\":{\"text\":\"Training and Validation Accuracy\"}},\"renderers\":[{\"type\":\"object\",\"name\":\"GlyphRenderer\",\"id\":\"p1237\",\"attributes\":{\"data_source\":{\"type\":\"object\",\"name\":\"ColumnDataSource\",\"id\":\"p1231\",\"attributes\":{\"selected\":{\"type\":\"object\",\"name\":\"Selection\",\"id\":\"p1232\",\"attributes\":{\"indices\":[],\"line_indices\":[]}},\"selection_policy\":{\"type\":\"object\",\"name\":\"UnionRenderers\",\"id\":\"p1233\"},\"data\":{\"type\":\"map\",\"entries\":[[\"x\",[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]],[\"y\",[0.5552763938903809,0.7185929417610168,0.8894472122192383,0.9748743772506714,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0]]]}}},\"view\":{\"type\":\"object\",\"name\":\"CDSView\",\"id\":\"p1238\",\"attributes\":{\"filter\":{\"type\":\"object\",\"name\":\"AllIndices\",\"id\":\"p1239\"}}},\"glyph\":{\"type\":\"object\",\"name\":\"Line\",\"id\":\"p1234\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"line_color\":\"blue\"}},\"nonselection_glyph\":{\"type\":\"object\",\"name\":\"Line\",\"id\":\"p1235\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"line_color\":\"blue\",\"line_alpha\":0.1}},\"muted_glyph\":{\"type\":\"object\",\"name\":\"Line\",\"id\":\"p1236\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"line_color\":\"blue\",\"line_alpha\":0.2}}}},{\"type\":\"object\",\"name\":\"GlyphRenderer\",\"id\":\"p1248\",\"attributes\":{\"data_source\":{\"type\":\"object\",\"name\":\"ColumnDataSource\",\"id\":\"p1242\",\"attributes\":{\"selected\":{\"type\":\"object\",\"name\":\"Selection\",\"id\":\"p1243\",\"attributes\":{\"indices\":[],\"line_indices\":[]}},\"selection_policy\":{\"type\":\"object\",\"name\":\"UnionRenderers\",\"id\":\"p1244\"},\"data\":{\"type\":\"map\",\"entries\":[[\"x\",[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25]],[\"y\",[0.029999999329447746,0.07000000029802322,0.2199999988079071,0.3400000035762787,0.2199999988079071,0.25,0.2800000011920929,0.3499999940395355,0.25999999046325684,0.25,0.25999999046325684,0.25999999046325684,0.25999999046325684,0.25999999046325684,0.25999999046325684,0.27000001072883606,0.27000001072883606,0.27000001072883606,0.27000001072883606,0.2800000011920929,0.2800000011920929,0.27000001072883606,0.2800000011920929,0.2800000011920929,0.2800000011920929]]]}}},\"view\":{\"type\":\"object\",\"name\":\"CDSView\",\"id\":\"p1249\",\"attributes\":{\"filter\":{\"type\":\"object\",\"name\":\"AllIndices\",\"id\":\"p1250\"}}},\"glyph\":{\"type\":\"object\",\"name\":\"Line\",\"id\":\"p1245\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"line_color\":\"red\"}},\"nonselection_glyph\":{\"type\":\"object\",\"name\":\"Line\",\"id\":\"p1246\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"line_color\":\"red\",\"line_alpha\":0.1}},\"muted_glyph\":{\"type\":\"object\",\"name\":\"Line\",\"id\":\"p1247\",\"attributes\":{\"x\":{\"type\":\"field\",\"field\":\"x\"},\"y\":{\"type\":\"field\",\"field\":\"y\"},\"line_color\":\"red\",\"line_alpha\":0.2}}}}],\"toolbar\":{\"type\":\"object\",\"name\":\"Toolbar\",\"id\":\"p1190\",\"attributes\":{\"tools\":[{\"type\":\"object\",\"name\":\"PanTool\",\"id\":\"p1216\"},{\"type\":\"object\",\"name\":\"WheelZoomTool\",\"id\":\"p1217\"},{\"type\":\"object\",\"name\":\"BoxZoomTool\",\"id\":\"p1218\",\"attributes\":{\"overlay\":{\"type\":\"object\",\"name\":\"BoxAnnotation\",\"id\":\"p1219\",\"attributes\":{\"syncable\":false,\"level\":\"overlay\",\"visible\":false,\"left_units\":\"canvas\",\"right_units\":\"canvas\",\"bottom_units\":\"canvas\",\"top_units\":\"canvas\",\"line_color\":\"black\",\"line_alpha\":1.0,\"line_width\":2,\"line_dash\":[4,4],\"fill_color\":\"lightgrey\",\"fill_alpha\":0.5}}}},{\"type\":\"object\",\"name\":\"SaveTool\",\"id\":\"p1220\"},{\"type\":\"object\",\"name\":\"ResetTool\",\"id\":\"p1221\"},{\"type\":\"object\",\"name\":\"HelpTool\",\"id\":\"p1222\"}]}},\"left\":[{\"type\":\"object\",\"name\":\"LinearAxis\",\"id\":\"p1209\",\"attributes\":{\"ticker\":{\"type\":\"object\",\"name\":\"BasicTicker\",\"id\":\"p1211\",\"attributes\":{\"mantissas\":[1,2,5]}},\"formatter\":{\"type\":\"object\",\"name\":\"BasicTickFormatter\",\"id\":\"p1212\"},\"axis_label\":\"Accuracy\",\"major_label_policy\":{\"type\":\"object\",\"name\":\"AllLabels\",\"id\":\"p1210\"}}}],\"below\":[{\"type\":\"object\",\"name\":\"LinearAxis\",\"id\":\"p1202\",\"attributes\":{\"ticker\":{\"type\":\"object\",\"name\":\"BasicTicker\",\"id\":\"p1204\",\"attributes\":{\"mantissas\":[1,2,5]}},\"formatter\":{\"type\":\"object\",\"name\":\"BasicTickFormatter\",\"id\":\"p1205\"},\"axis_label\":\"Epoch\",\"major_label_policy\":{\"type\":\"object\",\"name\":\"AllLabels\",\"id\":\"p1203\"}}}],\"center\":[{\"type\":\"object\",\"name\":\"Grid\",\"id\":\"p1208\",\"attributes\":{\"axis\":{\"id\":\"p1202\"}}},{\"type\":\"object\",\"name\":\"Grid\",\"id\":\"p1215\",\"attributes\":{\"dimension\":1,\"axis\":{\"id\":\"p1209\"}}},{\"type\":\"object\",\"name\":\"Legend\",\"id\":\"p1240\",\"attributes\":{\"items\":[{\"type\":\"object\",\"name\":\"LegendItem\",\"id\":\"p1241\",\"attributes\":{\"label\":{\"type\":\"value\",\"value\":\"Train Accuracy\"},\"renderers\":[{\"id\":\"p1237\"}]}},{\"type\":\"object\",\"name\":\"LegendItem\",\"id\":\"p1251\",\"attributes\":{\"label\":{\"type\":\"value\",\"value\":\"Validation Accuracy\"},\"renderers\":[{\"id\":\"p1248\"}]}}]}}]}}],\"callbacks\":{\"type\":\"map\"}}};\n  const render_items = [{\"docid\":\"6e977b72-4ff3-428f-a872-1385caf84b1c\",\"roots\":{\"p1184\":\"66dbfd25-b82b-491e-aeaa-ed5d3dd0de67\"},\"root_ids\":[\"p1184\"]}];\n  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n  }\n  if (root.Bokeh !== undefined) {\n    embed_document(root);\n  } else {\n    let attempts = 0;\n    const timer = setInterval(function(root) {\n      if (root.Bokeh !== undefined) {\n        clearInterval(timer);\n        embed_document(root);\n      } else {\n        attempts++;\n        if (attempts > 100) {\n          clearInterval(timer);\n          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n        }\n      }\n    }, 10, root)\n  }\n})(window);",
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "p1184"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# extract loss values from the training history\n",
    "train_loss = history.history['loss']\n",
    "valid_loss = history.history['val_loss']\n",
    "epochs = list(range(1, len(train_loss) + 1))\n",
    "\n",
    "# create plot\n",
    "p = figure(title=\"Training and Validation Loss\", x_axis_label=\"Epoch\", y_axis_label=\"Loss\")\n",
    "p.line(epochs, train_loss, legend_label=\"Train Loss\", line_color=\"blue\")\n",
    "p.line(epochs, valid_loss, legend_label=\"Validation Loss\", line_color=\"red\")\n",
    "\n",
    "# show it\n",
    "show(p)\n",
    "\n",
    "train_accuracy = history.history['accuracy']\n",
    "valid_accuracy = history.history['val_accuracy']\n",
    "epochs = list(range(1, len(train_accuracy) + 1))\n",
    "\n",
    "p = figure(title=\"Training and Validation Accuracy\", x_axis_label=\"Epoch\", y_axis_label=\"Accuracy\")\n",
    "p.line(epochs, train_accuracy, legend_label=\"Train Accuracy\", line_color=\"blue\")\n",
    "p.line(epochs, valid_accuracy, legend_label=\"Validation Accuracy\", line_color=\"red\")\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Image Augmentation\n",
    "\n",
    "Since our model only ended up giving a result barely higher than chance, we wanted to see if we could improve our results. Since we were working with a dataset on only a few hundred pictures we tried to increase the size of our dataset to try and improve our model's accuracy. We started by loading each datatype and class into lists of jpegs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path1 = glob.glob(\"data/test/hot_dog/*.jpg\")\n",
    "images_path2 = glob.glob(\"data/test/not_hot_dog/*.jpg\")\n",
    "images_path3 = glob.glob(\"data/train/hot_dog/*.jpg\")\n",
    "images_path4 = glob.glob(\"data/train/not_hot_dog/*.jpg\")\n",
    "\n",
    "images_test_hd = []\n",
    "images_test_nhd = []\n",
    "images_train_hd = []\n",
    "images_train_nhd = []\n",
    "for img_path in images_path1:\n",
    "    img = cv2.imread(img_path,0)\n",
    "    images_test_hd.append(img)\n",
    "for img_path in images_path2:\n",
    "    img = cv2.imread(img_path,0)\n",
    "    images_test_nhd.append(img)\n",
    "for img_path in images_path3:\n",
    "    img = cv2.imread(img_path,0)\n",
    "    images_train_hd.append(img)\n",
    "for img_path in images_path4:\n",
    "    img = cv2.imread(img_path,0)\n",
    "    images_train_nhd.append(img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To increase the size of our dataset, we augmented our existing photos and added them to the list of the our pictures. There were five operations we performed on each food picture: a horizontal flip, a vertical flip, a flip both ways, a random magnitude of blurring, and a random change of light exposure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mirror = iaa.Sequential([\n",
    "    iaa.Fliplr(1),\n",
    "    ])\n",
    "flip = iaa.Sequential([\n",
    "    iaa.Flipud(1),\n",
    "    ])\n",
    "mf = iaa.Sequential([\n",
    "    iaa.Fliplr(1),\n",
    "    iaa.Flipud(1),\n",
    "    ])\n",
    "blur = iaa.Sequential([\n",
    "    iaa.AverageBlur(2,7)\n",
    "    ])\n",
    "contrast = iaa.Sequential([\n",
    "    iaa.LinearContrast((.7,1.3))\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each existing photo, we added three differently-blurred instances and one instance of each other augmentation to the data pool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_images_test_hd = mirror(images = images_test_hd)\n",
    "f_images_test_hd = flip(images = images_test_hd)\n",
    "mf_images_test_hd = mf(images = images_test_hd)\n",
    "b_images_test_hd = blur(images = images_test_hd) + blur(images = images_test_hd)+ blur(images = images_test_hd)\n",
    "c_images_test_hd = contrast(images = images_test_hd)\n",
    "\n",
    "m_images_test_nhd = mirror(images = images_test_nhd)\n",
    "f_images_test_nhd = flip(images = images_test_nhd)\n",
    "mf_images_test_nhd = mf(images = images_test_nhd)\n",
    "b_images_test_nhd = blur(images = images_test_nhd) + blur(images = images_test_nhd) + blur(images = images_test_nhd)\n",
    "c_images_test_nhd = contrast(images = images_test_nhd)\n",
    "\n",
    "m_images_train_hd = mirror(images = images_train_hd)\n",
    "f_images_train_hd = flip(images = images_train_hd)\n",
    "mf_images_train_hd = mf(images = images_train_hd)\n",
    "b_images_train_hd = blur(images = images_train_hd) + blur(images = images_train_hd)+ blur(images = images_train_hd)\n",
    "c_images_train_hd = contrast(images = images_train_hd)\n",
    "\n",
    "\n",
    "m_images_train_nhd = mirror(images = images_train_nhd)\n",
    "f_images_train_nhd = flip(images = images_train_nhd)\n",
    "mf_images_train_nhd = mf(images = images_train_nhd)\n",
    "b_images_train_nhd = blur(images = images_train_nhd) + blur( images = images_train_nhd)+ blur( images = images_train_nhd)\n",
    "c_images_train_nhd = contrast(images = images_train_nhd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_test_hd = images_test_hd + m_images_test_hd + f_images_test_hd + mf_images_test_hd + b_images_test_hd + c_images_test_hd\n",
    "images_test_nhd = images_test_nhd + m_images_test_nhd + f_images_test_nhd + mf_images_test_nhd + b_images_test_nhd + c_images_test_nhd\n",
    "images_train_hd = images_train_hd + m_images_train_hd + f_images_train_hd + mf_images_train_hd + b_images_train_hd + c_images_train_hd\n",
    "images_train_nhd = images_train_nhd + m_images_train_nhd + f_images_train_nhd + mf_images_train_nhd + b_images_train_nhd + c_images_train_nhd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After saving the new lists to a new directory, we could pull the larger number of pictures back into our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_no = 1\n",
    "for image in images_test_hd :\n",
    "    # [...]\n",
    "    name = 'data/new/test/hot_dog/' + str(image_no) + '.jpg'\n",
    "    photo = Image.fromarray(image)\n",
    "    photo.save(name, 'JPEG')\n",
    "    image_no += 1\n",
    "\n",
    "image_no = 1\n",
    "\n",
    "for image in images_test_nhd :\n",
    "    # [...]\n",
    "    name = 'data/new/test/not_hot_dog/' + str(image_no) + '.jpg'\n",
    "    photo = Image.fromarray(image)\n",
    "    photo.save(name, 'JPEG')\n",
    "    image_no += 1\n",
    "\n",
    "image_no = 1\n",
    "\n",
    "for image in images_train_hd :\n",
    "    # [...]\n",
    "    name = 'data/new/train/hot_dog/' + str(image_no) + '.jpg'\n",
    "    photo = Image.fromarray(image)\n",
    "    photo.save(name, 'JPEG')\n",
    "    image_no += 1\n",
    "\n",
    "image_no = 1\n",
    "\n",
    "for image in images_train_nhd :\n",
    "    # [...]\n",
    "    name = 'data/new/train/not_hot_dog/' + str(image_no) + '.jpg'\n",
    "    photo = Image.fromarray(image)\n",
    "    photo.save(name, 'JPEG')\n",
    "    image_no += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 100, 100\n",
    "input_shape = (img_width, img_height, 1)\n",
    "batch_size = 1400\n",
    "no_epochs = 25\n",
    "no_classes = 2\n",
    "validation_split = 0.1\n",
    "verbosity = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_load_data(data_type, class_name):\n",
    "    instances = []\n",
    "    classes = []\n",
    "    for filepath in os.listdir(f'data/new/{data_type}/{class_name}'):\n",
    "        resized_image = cv2.imread(f'data/new/{data_type}/{class_name}/{format(filepath)}', 0)\n",
    "        resized_image = cv2.resize(resized_image, (img_width, img_height))\n",
    "        instances.append(resized_image)\n",
    "        classes.append(0 if class_name == 'not_hot_dog' else 1)\n",
    "    return (instances, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train_nh, y_train_nh = new_load_data(data_type='train', class_name='not_hot_dog')\n",
    "X_train_h, y_train_h = new_load_data(data_type='train', class_name='hot_dog')\n",
    "X_train = np.array(X_train_nh + X_train_h)\n",
    "X_train = X_train.reshape((X_train.shape[0], img_width, img_height, 1))\n",
    "y_train = np.array(y_train_nh + y_train_h)\n",
    "\n",
    "\n",
    "X_test_nh, y_test_nh = new_load_data(data_type='test', class_name='not_hot_dog')\n",
    "X_test_h, y_test_h = new_load_data(data_type='test', class_name='hot_dog')\n",
    "X_test = np.array(X_test_nh + X_test_h)\n",
    "X_test = X_test.reshape((X_test.shape[0], img_width, img_height, 1))\n",
    "y_test = np.array(y_test_nh + y_test_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(25, kernel_size=(3, 3), activation=\"relu\", input_shape=input_shape))\n",
    "model.add(Conv2D(50, kernel_size=(3, 3), activation=\"relu\"))\n",
    "model.add(Conv2D(100, kernel_size=(3, 3), activation=\"relu\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation=\"relu\"))\n",
    "model.add(Dense(num_classes, activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss=tensorflow.keras.losses.sparse_categorical_crossentropy,\n",
    "              optimizer=tensorflow.keras.optimizers.Adam(),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "            batch_size=batch_size,\n",
    "            epochs=num_epochs,\n",
    "            shuffle=True,\n",
    "            verbose=1,\n",
    "            validation_split=validation_split)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, the accuracy of the model was not increased substantially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(model.predict(X_test), axis=-1)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = cm.ravel()\n",
    "pd.DataFrame({\n",
    "    \"Metric\": [\"Accuracy\", \"Precision\", \"Recall\", \"F1\"],\n",
    "    \"Value\": [(tp+tn)/(tp+fp+fn+tn), tp/(tp+fp), tp/(tp+fn), (2*tp/(tp+fp))*(tp/(tp+fn)) / ((tp/(tp+fp))+(tp/(tp+fn)))]\n",
    "})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown in the loss plot below, the model still has a gap between training and validation loss.\n",
    "We may have to investigate other methods to reduce overfitting, such as adding a dropout or max\n",
    "pool layer to the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = history.history['loss']\n",
    "valid_loss = history.history['val_loss']\n",
    "epochs = list(range(1, len(train_loss) + 1))\n",
    "\n",
    "\n",
    "p = figure(title=\"Training and Validation Loss\", x_axis_label=\"Epoch\", y_axis_label=\"Loss\")\n",
    "p.line(epochs, train_loss, legend_label=\"Train Loss\", line_color=\"blue\")\n",
    "p.line(epochs, valid_loss, legend_label=\"Validation Loss\", line_color=\"red\")\n",
    "\n",
    "\n",
    "show(p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
